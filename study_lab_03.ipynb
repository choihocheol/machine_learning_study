{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 데이터셋 가져오기\n",
    "mnist란 미국 국립표준기술연구소의 손으로 쓴 글자 데이터셋에서 숫자만 뽑아낸 데이터셋입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.path.join(os.getcwd(), 'mnist.npz')\n",
    "\n",
    "(train_data, train_label), (test_data, test_label) = tf.keras.datasets.mnist.load_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터셋의 train 데이터셋은 60000개, test 데이터셋은 10000개입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[5 0 4 ... 5 6 8]\n",
      "---------------------------\n",
      "(10000, 28, 28)\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_label)\n",
    "print('-'*27)\n",
    "print(test_data.shape)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 데이터셋 maplotlib를 이용한 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_img(i):\n",
    "    plt.title('This is {}'.format(train_label[i]))\n",
    "    plt.imshow(train_data[i], cmap='gray')\n",
    "    plt.show()\n",
    "show_img(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리(Data Preprocessing)\n",
    "\n",
    "tensorflow는 shape이 [batch_size, height, width, color_channel] 으로 되어야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(train_data, axis=-1)\n",
    "test_data = np.expand_dims(test_data, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data / 255.0\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "train_label = tf.keras.utils.to_categorical(train_label, 10)\n",
    "test_label = tf.keras.utils.to_categorical(test_label, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "train_dataset_num = len(train_data) // batch_size\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label)).\\\n",
    "    shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=batch_size).\\\n",
    "    batch(batch_size, drop_remainder=True)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_label)).\\\n",
    "    shuffle(buffer_size=100000).\\\n",
    "    prefetch(buffer_size=len(test_data)).\\\n",
    "    batch(len(test_data), drop_remainder=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.keras.initializers.RandomNormal()\n",
    "label_dim = 10\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=256, use_bias=True, kernel_initializer=weight))\n",
    "model.add(tf.keras.layers.Activation(tf.keras.activations.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(units=512, use_bias=True, kernel_initializer=weight))\n",
    "model.add(tf.keras.layers.Activation(tf.keras.activations.sigmoid))\n",
    "model.add(tf.keras.layers.Dense(units=label_dim, use_bias=True, kernel_initializer=weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN 학습 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch:     0, Process:     0/468, Loss: 2.49096, Accuracy:   7.8%\n",
      "Epoch:     0, Process:     1/468, Loss: 2.32250, Accuracy:   8.6%\n",
      "Epoch:     0, Process:     2/468, Loss: 2.34287, Accuracy:  12.5%\n",
      "Epoch:     0, Process:     3/468, Loss: 2.34698, Accuracy:  16.4%\n",
      "Epoch:     0, Process:     4/468, Loss: 2.37297, Accuracy:   7.0%\n",
      "Epoch:     0, Process:     5/468, Loss: 2.38250, Accuracy:   6.2%\n",
      "Epoch:     0, Process:     6/468, Loss: 2.20438, Accuracy:  37.5%\n",
      "Epoch:     0, Process:     7/468, Loss: 2.27093, Accuracy:  16.4%\n",
      "Epoch:     0, Process:     8/468, Loss: 2.22630, Accuracy:  32.0%\n",
      "Epoch:     0, Process:     9/468, Loss: 2.25364, Accuracy:  17.2%\n",
      "Epoch:     0, Process:    10/468, Loss: 2.23038, Accuracy:  13.3%\n",
      "Epoch:     0, Process:    11/468, Loss: 2.18518, Accuracy:  22.7%\n",
      "Epoch:     0, Process:    12/468, Loss: 2.15767, Accuracy:  24.2%\n",
      "Epoch:     0, Process:    13/468, Loss: 2.11585, Accuracy:  21.1%\n",
      "Epoch:     0, Process:    14/468, Loss: 2.10866, Accuracy:  23.4%\n",
      "Epoch:     0, Process:    15/468, Loss: 2.04321, Accuracy:  35.2%\n",
      "Epoch:     0, Process:    16/468, Loss: 2.14010, Accuracy:  28.1%\n",
      "Epoch:     0, Process:    17/468, Loss: 2.07695, Accuracy:  31.2%\n",
      "Epoch:     0, Process:    18/468, Loss: 2.08718, Accuracy:  38.3%\n",
      "Epoch:     0, Process:    19/468, Loss: 1.99408, Accuracy:  46.9%\n",
      "Epoch:     0, Process:    20/468, Loss: 2.04310, Accuracy:  35.9%\n",
      "Epoch:     0, Process:    21/468, Loss: 1.98562, Accuracy:  37.5%\n",
      "Epoch:     0, Process:    22/468, Loss: 1.98321, Accuracy:  38.3%\n",
      "Epoch:     0, Process:    23/468, Loss: 1.94304, Accuracy:  45.3%\n",
      "Epoch:     0, Process:    24/468, Loss: 1.94244, Accuracy:  45.3%\n",
      "Epoch:     0, Process:    25/468, Loss: 1.89081, Accuracy:  55.5%\n",
      "Epoch:     0, Process:    26/468, Loss: 1.83178, Accuracy:  59.4%\n",
      "Epoch:     0, Process:    27/468, Loss: 1.81230, Accuracy:  58.6%\n",
      "Epoch:     0, Process:    28/468, Loss: 1.80330, Accuracy:  64.8%\n",
      "Epoch:     0, Process:    29/468, Loss: 1.76147, Accuracy:  60.2%\n",
      "Epoch:     0, Process:    30/468, Loss: 1.70957, Accuracy:  64.1%\n",
      "Epoch:     0, Process:    31/468, Loss: 1.63841, Accuracy:  59.4%\n",
      "Epoch:     0, Process:    32/468, Loss: 1.63104, Accuracy:  60.9%\n",
      "Epoch:     0, Process:    33/468, Loss: 1.61505, Accuracy:  60.2%\n",
      "Epoch:     0, Process:    34/468, Loss: 1.64687, Accuracy:  62.5%\n",
      "Epoch:     0, Process:    35/468, Loss: 1.54396, Accuracy:  64.8%\n",
      "Epoch:     0, Process:    36/468, Loss: 1.59076, Accuracy:  54.7%\n",
      "Epoch:     0, Process:    37/468, Loss: 1.48894, Accuracy:  64.1%\n",
      "Epoch:     0, Process:    38/468, Loss: 1.45818, Accuracy:  63.3%\n",
      "Epoch:     0, Process:    39/468, Loss: 1.45319, Accuracy:  65.6%\n",
      "Epoch:     0, Process:    40/468, Loss: 1.40309, Accuracy:  70.3%\n",
      "Epoch:     0, Process:    41/468, Loss: 1.40089, Accuracy:  69.5%\n",
      "Epoch:     0, Process:    42/468, Loss: 1.38589, Accuracy:  68.8%\n",
      "Epoch:     0, Process:    43/468, Loss: 1.34783, Accuracy:  75.8%\n",
      "Epoch:     0, Process:    44/468, Loss: 1.31783, Accuracy:  71.9%\n",
      "Epoch:     0, Process:    45/468, Loss: 1.26648, Accuracy:  74.2%\n",
      "Epoch:     0, Process:    46/468, Loss: 1.28103, Accuracy:  74.2%\n",
      "Epoch:     0, Process:    47/468, Loss: 1.22760, Accuracy:  78.9%\n",
      "Epoch:     0, Process:    48/468, Loss: 1.16583, Accuracy:  75.0%\n",
      "Epoch:     0, Process:    49/468, Loss: 1.18825, Accuracy:  75.0%\n",
      "Epoch:     0, Process:    50/468, Loss: 1.16789, Accuracy:  69.5%\n",
      "Epoch:     0, Process:    51/468, Loss: 1.12397, Accuracy:  73.4%\n",
      "Epoch:     0, Process:    52/468, Loss: 1.10107, Accuracy:  70.3%\n",
      "Epoch:     0, Process:    53/468, Loss: 1.10908, Accuracy:  68.8%\n",
      "Epoch:     0, Process:    54/468, Loss: 1.14247, Accuracy:  64.8%\n",
      "Epoch:     0, Process:    55/468, Loss: 1.06727, Accuracy:  71.9%\n",
      "Epoch:     0, Process:    56/468, Loss: 1.06982, Accuracy:  68.8%\n",
      "Epoch:     0, Process:    57/468, Loss: 1.03746, Accuracy:  71.1%\n",
      "Epoch:     0, Process:    58/468, Loss: 0.99714, Accuracy:  77.3%\n",
      "Epoch:     0, Process:    59/468, Loss: 0.96733, Accuracy:  75.8%\n",
      "Epoch:     0, Process:    60/468, Loss: 0.89543, Accuracy:  82.8%\n",
      "Epoch:     0, Process:    61/468, Loss: 0.93105, Accuracy:  82.0%\n",
      "Epoch:     0, Process:    62/468, Loss: 0.94432, Accuracy:  81.2%\n",
      "Epoch:     0, Process:    63/468, Loss: 0.83555, Accuracy:  87.5%\n",
      "Epoch:     0, Process:    64/468, Loss: 0.88047, Accuracy:  81.2%\n",
      "Epoch:     0, Process:    65/468, Loss: 0.81554, Accuracy:  79.7%\n",
      "Epoch:     0, Process:    66/468, Loss: 0.85664, Accuracy:  82.0%\n",
      "Epoch:     0, Process:    67/468, Loss: 0.96087, Accuracy:  70.3%\n",
      "Epoch:     0, Process:    68/468, Loss: 0.90451, Accuracy:  76.6%\n",
      "Epoch:     0, Process:    69/468, Loss: 0.88690, Accuracy:  74.2%\n",
      "Epoch:     0, Process:    70/468, Loss: 0.77681, Accuracy:  78.9%\n",
      "Epoch:     0, Process:    71/468, Loss: 0.82446, Accuracy:  79.7%\n",
      "Epoch:     0, Process:    72/468, Loss: 0.80529, Accuracy:  81.2%\n",
      "Epoch:     0, Process:    73/468, Loss: 0.97797, Accuracy:  71.9%\n",
      "Epoch:     0, Process:    74/468, Loss: 0.73434, Accuracy:  84.4%\n",
      "Epoch:     0, Process:    75/468, Loss: 0.71206, Accuracy:  84.4%\n",
      "Epoch:     0, Process:    76/468, Loss: 0.73725, Accuracy:  85.2%\n",
      "Epoch:     0, Process:    77/468, Loss: 0.72517, Accuracy:  83.6%\n",
      "Epoch:     0, Process:    78/468, Loss: 0.85024, Accuracy:  79.7%\n",
      "Epoch:     0, Process:    79/468, Loss: 0.65827, Accuracy:  83.6%\n",
      "Epoch:     0, Process:    80/468, Loss: 0.69476, Accuracy:  80.5%\n",
      "Epoch:     0, Process:    81/468, Loss: 0.73948, Accuracy:  80.5%\n",
      "Epoch:     0, Process:    82/468, Loss: 0.63858, Accuracy:  87.5%\n",
      "Epoch:     0, Process:    83/468, Loss: 0.65604, Accuracy:  82.0%\n",
      "Epoch:     0, Process:    84/468, Loss: 0.75500, Accuracy:  78.9%\n",
      "Epoch:     0, Process:    85/468, Loss: 0.71551, Accuracy:  81.2%\n",
      "Epoch:     0, Process:    86/468, Loss: 0.68810, Accuracy:  85.9%\n",
      "Epoch:     0, Process:    87/468, Loss: 0.72050, Accuracy:  86.7%\n",
      "Epoch:     0, Process:    88/468, Loss: 0.62668, Accuracy:  82.8%\n",
      "Epoch:     0, Process:    89/468, Loss: 0.63997, Accuracy:  81.2%\n",
      "Epoch:     0, Process:    90/468, Loss: 0.63172, Accuracy:  87.5%\n",
      "Epoch:     0, Process:    91/468, Loss: 0.62783, Accuracy:  85.9%\n",
      "Epoch:     0, Process:    92/468, Loss: 0.57013, Accuracy:  85.9%\n",
      "Epoch:     0, Process:    93/468, Loss: 0.61905, Accuracy:  82.8%\n",
      "Epoch:     0, Process:    94/468, Loss: 0.63646, Accuracy:  80.5%\n",
      "Epoch:     0, Process:    95/468, Loss: 0.50369, Accuracy:  88.3%\n",
      "Epoch:     0, Process:    96/468, Loss: 0.58558, Accuracy:  82.8%\n",
      "Epoch:     0, Process:    97/468, Loss: 0.61078, Accuracy:  82.0%\n",
      "Epoch:     0, Process:    98/468, Loss: 0.54655, Accuracy:  88.3%\n",
      "Epoch:     0, Process:    99/468, Loss: 0.46294, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   100/468, Loss: 0.49394, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   101/468, Loss: 0.50337, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   102/468, Loss: 0.54986, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   103/468, Loss: 0.58971, Accuracy:  84.4%\n",
      "Epoch:     0, Process:   104/468, Loss: 0.47817, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   105/468, Loss: 0.54876, Accuracy:  81.2%\n",
      "Epoch:     0, Process:   106/468, Loss: 0.60997, Accuracy:  83.6%\n",
      "Epoch:     0, Process:   107/468, Loss: 0.47837, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   108/468, Loss: 0.54918, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   109/468, Loss: 0.58324, Accuracy:  80.5%\n",
      "Epoch:     0, Process:   110/468, Loss: 0.54407, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   111/468, Loss: 0.50248, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   112/468, Loss: 0.48949, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   113/468, Loss: 0.49790, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   114/468, Loss: 0.60274, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   115/468, Loss: 0.48574, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   116/468, Loss: 0.54755, Accuracy:  83.6%\n",
      "Epoch:     0, Process:   117/468, Loss: 0.47100, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   118/468, Loss: 0.48429, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   119/468, Loss: 0.44270, Accuracy:  89.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     0, Process:   120/468, Loss: 0.50778, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   121/468, Loss: 0.60069, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   122/468, Loss: 0.46782, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   123/468, Loss: 0.46442, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   124/468, Loss: 0.51394, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   125/468, Loss: 0.55016, Accuracy:  84.4%\n",
      "Epoch:     0, Process:   126/468, Loss: 0.44166, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   127/468, Loss: 0.39408, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   128/468, Loss: 0.48563, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   129/468, Loss: 0.51464, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   130/468, Loss: 0.54273, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   131/468, Loss: 0.51101, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   132/468, Loss: 0.48657, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   133/468, Loss: 0.44462, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   134/468, Loss: 0.41430, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   135/468, Loss: 0.45674, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   136/468, Loss: 0.39567, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   137/468, Loss: 0.42722, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   138/468, Loss: 0.50753, Accuracy:  84.4%\n",
      "Epoch:     0, Process:   139/468, Loss: 0.33788, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   140/468, Loss: 0.36250, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   141/468, Loss: 0.49837, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   142/468, Loss: 0.52754, Accuracy:  84.4%\n",
      "Epoch:     0, Process:   143/468, Loss: 0.53650, Accuracy:  82.8%\n",
      "Epoch:     0, Process:   144/468, Loss: 0.41410, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   145/468, Loss: 0.40047, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   146/468, Loss: 0.38979, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   147/468, Loss: 0.49233, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   148/468, Loss: 0.42942, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   149/468, Loss: 0.32719, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   150/468, Loss: 0.35791, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   151/468, Loss: 0.48887, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   152/468, Loss: 0.44632, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   153/468, Loss: 0.46153, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   154/468, Loss: 0.30254, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   155/468, Loss: 0.47980, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   156/468, Loss: 0.42197, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   157/468, Loss: 0.36266, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   158/468, Loss: 0.44170, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   159/468, Loss: 0.39364, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   160/468, Loss: 0.45801, Accuracy:  82.8%\n",
      "Epoch:     0, Process:   161/468, Loss: 0.51615, Accuracy:  82.8%\n",
      "Epoch:     0, Process:   162/468, Loss: 0.38893, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   163/468, Loss: 0.39961, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   164/468, Loss: 0.31923, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   165/468, Loss: 0.36560, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   166/468, Loss: 0.34704, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   167/468, Loss: 0.30431, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   168/468, Loss: 0.35820, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   169/468, Loss: 0.49973, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   170/468, Loss: 0.43594, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   171/468, Loss: 0.43745, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   172/468, Loss: 0.33109, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   173/468, Loss: 0.48687, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   174/468, Loss: 0.40702, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   175/468, Loss: 0.36391, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   176/468, Loss: 0.42881, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   177/468, Loss: 0.29862, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   178/468, Loss: 0.32596, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   179/468, Loss: 0.42183, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   180/468, Loss: 0.39759, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   181/468, Loss: 0.34353, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   182/468, Loss: 0.38425, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   183/468, Loss: 0.53079, Accuracy:  80.5%\n",
      "Epoch:     0, Process:   184/468, Loss: 0.42976, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   185/468, Loss: 0.31047, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   186/468, Loss: 0.45266, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   187/468, Loss: 0.39101, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   188/468, Loss: 0.32625, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   189/468, Loss: 0.30242, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   190/468, Loss: 0.37169, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   191/468, Loss: 0.29163, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   192/468, Loss: 0.33310, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   193/468, Loss: 0.49692, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   194/468, Loss: 0.36116, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   195/468, Loss: 0.35636, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   196/468, Loss: 0.35680, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   197/468, Loss: 0.37406, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   198/468, Loss: 0.40222, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   199/468, Loss: 0.31646, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   200/468, Loss: 0.48773, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   201/468, Loss: 0.45793, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   202/468, Loss: 0.38718, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   203/468, Loss: 0.32144, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   204/468, Loss: 0.33218, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   205/468, Loss: 0.41766, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   206/468, Loss: 0.37502, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   207/468, Loss: 0.47452, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   208/468, Loss: 0.33905, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   209/468, Loss: 0.27661, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   210/468, Loss: 0.38317, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   211/468, Loss: 0.47923, Accuracy:  83.6%\n",
      "Epoch:     0, Process:   212/468, Loss: 0.39822, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   213/468, Loss: 0.44905, Accuracy:  83.6%\n",
      "Epoch:     0, Process:   214/468, Loss: 0.26864, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   215/468, Loss: 0.36897, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   216/468, Loss: 0.41466, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   217/468, Loss: 0.36143, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   218/468, Loss: 0.33861, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   219/468, Loss: 0.26698, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   220/468, Loss: 0.33849, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   221/468, Loss: 0.39904, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   222/468, Loss: 0.41142, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   223/468, Loss: 0.39203, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   224/468, Loss: 0.38188, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   225/468, Loss: 0.47739, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   226/468, Loss: 0.35930, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   227/468, Loss: 0.39544, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   228/468, Loss: 0.38371, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   229/468, Loss: 0.34069, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   230/468, Loss: 0.39754, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   231/468, Loss: 0.26904, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   232/468, Loss: 0.35686, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   233/468, Loss: 0.31835, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   234/468, Loss: 0.28820, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   235/468, Loss: 0.26432, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   236/468, Loss: 0.42993, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   237/468, Loss: 0.33625, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   238/468, Loss: 0.41781, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   239/468, Loss: 0.37309, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   240/468, Loss: 0.30704, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   241/468, Loss: 0.44982, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   242/468, Loss: 0.33095, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   243/468, Loss: 0.29596, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   244/468, Loss: 0.39806, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   245/468, Loss: 0.52969, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   246/468, Loss: 0.37920, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   247/468, Loss: 0.30728, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   248/468, Loss: 0.35432, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   249/468, Loss: 0.37937, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   250/468, Loss: 0.37899, Accuracy:  89.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     0, Process:   251/468, Loss: 0.42326, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   252/468, Loss: 0.24672, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   253/468, Loss: 0.35119, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   254/468, Loss: 0.32800, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   255/468, Loss: 0.27105, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   256/468, Loss: 0.38790, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   257/468, Loss: 0.41271, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   258/468, Loss: 0.25693, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   259/468, Loss: 0.44515, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   260/468, Loss: 0.33898, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   261/468, Loss: 0.24733, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   262/468, Loss: 0.28666, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   263/468, Loss: 0.33736, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   264/468, Loss: 0.28137, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   265/468, Loss: 0.34693, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   266/468, Loss: 0.36401, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   267/468, Loss: 0.32744, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   268/468, Loss: 0.30759, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   269/468, Loss: 0.27151, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   270/468, Loss: 0.30015, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   271/468, Loss: 0.41795, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   272/468, Loss: 0.39155, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   273/468, Loss: 0.45902, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   274/468, Loss: 0.39755, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   275/468, Loss: 0.28704, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   276/468, Loss: 0.28887, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   277/468, Loss: 0.30370, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   278/468, Loss: 0.32799, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   279/468, Loss: 0.32453, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   280/468, Loss: 0.29349, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   281/468, Loss: 0.52596, Accuracy:  83.6%\n",
      "Epoch:     0, Process:   282/468, Loss: 0.35649, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   283/468, Loss: 0.31110, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   284/468, Loss: 0.32640, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   285/468, Loss: 0.30771, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   286/468, Loss: 0.25101, Accuracy:  96.1%\n",
      "Epoch:     0, Process:   287/468, Loss: 0.44137, Accuracy:  85.2%\n",
      "Epoch:     0, Process:   288/468, Loss: 0.27169, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   289/468, Loss: 0.36432, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   290/468, Loss: 0.25586, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   291/468, Loss: 0.23715, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   292/468, Loss: 0.23649, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   293/468, Loss: 0.44511, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   294/468, Loss: 0.29044, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   295/468, Loss: 0.29779, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   296/468, Loss: 0.29848, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   297/468, Loss: 0.16507, Accuracy:  95.3%\n",
      "Epoch:     0, Process:   298/468, Loss: 0.32555, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   299/468, Loss: 0.35907, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   300/468, Loss: 0.29777, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   301/468, Loss: 0.36960, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   302/468, Loss: 0.33055, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   303/468, Loss: 0.24790, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   304/468, Loss: 0.24368, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   305/468, Loss: 0.39520, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   306/468, Loss: 0.27070, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   307/468, Loss: 0.27928, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   308/468, Loss: 0.28105, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   309/468, Loss: 0.32902, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   310/468, Loss: 0.33694, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   311/468, Loss: 0.30828, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   312/468, Loss: 0.46059, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   313/468, Loss: 0.29711, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   314/468, Loss: 0.23928, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   315/468, Loss: 0.29431, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   316/468, Loss: 0.37193, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   317/468, Loss: 0.21871, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   318/468, Loss: 0.35441, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   319/468, Loss: 0.31295, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   320/468, Loss: 0.33838, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   321/468, Loss: 0.23328, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   322/468, Loss: 0.28895, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   323/468, Loss: 0.34657, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   324/468, Loss: 0.38996, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   325/468, Loss: 0.23543, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   326/468, Loss: 0.24377, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   327/468, Loss: 0.39145, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   328/468, Loss: 0.28059, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   329/468, Loss: 0.42557, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   330/468, Loss: 0.36307, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   331/468, Loss: 0.27783, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   332/468, Loss: 0.23519, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   333/468, Loss: 0.26398, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   334/468, Loss: 0.26848, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   335/468, Loss: 0.24672, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   336/468, Loss: 0.34654, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   337/468, Loss: 0.20728, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   338/468, Loss: 0.19580, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   339/468, Loss: 0.40095, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   340/468, Loss: 0.23388, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   341/468, Loss: 0.27138, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   342/468, Loss: 0.25406, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   343/468, Loss: 0.24372, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   344/468, Loss: 0.25834, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   345/468, Loss: 0.22368, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   346/468, Loss: 0.29863, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   347/468, Loss: 0.29513, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   348/468, Loss: 0.21146, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   349/468, Loss: 0.29205, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   350/468, Loss: 0.21673, Accuracy:  95.3%\n",
      "Epoch:     0, Process:   351/468, Loss: 0.26547, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   352/468, Loss: 0.29198, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   353/468, Loss: 0.29775, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   354/468, Loss: 0.23682, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   355/468, Loss: 0.24412, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   356/468, Loss: 0.36362, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   357/468, Loss: 0.24747, Accuracy:  95.3%\n",
      "Epoch:     0, Process:   358/468, Loss: 0.22786, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   359/468, Loss: 0.21690, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   360/468, Loss: 0.43124, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   361/468, Loss: 0.32453, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   362/468, Loss: 0.20968, Accuracy:  95.3%\n",
      "Epoch:     0, Process:   363/468, Loss: 0.23043, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   364/468, Loss: 0.28521, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   365/468, Loss: 0.29052, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   366/468, Loss: 0.33925, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   367/468, Loss: 0.22932, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   368/468, Loss: 0.34838, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   369/468, Loss: 0.31190, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   370/468, Loss: 0.21400, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   371/468, Loss: 0.31064, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   372/468, Loss: 0.36429, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   373/468, Loss: 0.28983, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   374/468, Loss: 0.25415, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   375/468, Loss: 0.22628, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   376/468, Loss: 0.26140, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   377/468, Loss: 0.35416, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   378/468, Loss: 0.28314, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   379/468, Loss: 0.47139, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   380/468, Loss: 0.25973, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   381/468, Loss: 0.22339, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   382/468, Loss: 0.28804, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   383/468, Loss: 0.25973, Accuracy:  93.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     0, Process:   384/468, Loss: 0.22630, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   385/468, Loss: 0.24672, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   386/468, Loss: 0.34202, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   387/468, Loss: 0.38108, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   388/468, Loss: 0.27226, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   389/468, Loss: 0.34362, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   390/468, Loss: 0.14030, Accuracy:  96.1%\n",
      "Epoch:     0, Process:   391/468, Loss: 0.28614, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   392/468, Loss: 0.37311, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   393/468, Loss: 0.30520, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   394/468, Loss: 0.35189, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   395/468, Loss: 0.28378, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   396/468, Loss: 0.18660, Accuracy:  96.1%\n",
      "Epoch:     0, Process:   397/468, Loss: 0.35266, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   398/468, Loss: 0.27233, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   399/468, Loss: 0.25600, Accuracy:  96.1%\n",
      "Epoch:     0, Process:   400/468, Loss: 0.20913, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   401/468, Loss: 0.33743, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   402/468, Loss: 0.36282, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   403/468, Loss: 0.32245, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   404/468, Loss: 0.26947, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   405/468, Loss: 0.38951, Accuracy:  85.9%\n",
      "Epoch:     0, Process:   406/468, Loss: 0.18734, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   407/468, Loss: 0.37889, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   408/468, Loss: 0.25015, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   409/468, Loss: 0.31593, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   410/468, Loss: 0.21668, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   411/468, Loss: 0.31452, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   412/468, Loss: 0.37722, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   413/468, Loss: 0.38086, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   414/468, Loss: 0.23685, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   415/468, Loss: 0.28395, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   416/468, Loss: 0.23585, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   417/468, Loss: 0.21743, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   418/468, Loss: 0.18420, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   419/468, Loss: 0.26735, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   420/468, Loss: 0.25483, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   421/468, Loss: 0.31079, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   422/468, Loss: 0.19537, Accuracy:  95.3%\n",
      "Epoch:     0, Process:   423/468, Loss: 0.25317, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   424/468, Loss: 0.24005, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   425/468, Loss: 0.20429, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   426/468, Loss: 0.30542, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   427/468, Loss: 0.42621, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   428/468, Loss: 0.15962, Accuracy:  96.1%\n",
      "Epoch:     0, Process:   429/468, Loss: 0.25348, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   430/468, Loss: 0.25717, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   431/468, Loss: 0.20327, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   432/468, Loss: 0.30057, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   433/468, Loss: 0.21060, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   434/468, Loss: 0.21445, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   435/468, Loss: 0.27300, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   436/468, Loss: 0.23808, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   437/468, Loss: 0.32715, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   438/468, Loss: 0.25249, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   439/468, Loss: 0.17764, Accuracy:  96.1%\n",
      "Epoch:     0, Process:   440/468, Loss: 0.20466, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   441/468, Loss: 0.26251, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   442/468, Loss: 0.26861, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   443/468, Loss: 0.22072, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   444/468, Loss: 0.37629, Accuracy:  86.7%\n",
      "Epoch:     0, Process:   445/468, Loss: 0.13459, Accuracy:  94.5%\n",
      "Epoch:     0, Process:   446/468, Loss: 0.32302, Accuracy:  89.1%\n",
      "Epoch:     0, Process:   447/468, Loss: 0.30717, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   448/468, Loss: 0.28563, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   449/468, Loss: 0.15699, Accuracy:  96.1%\n",
      "Epoch:     0, Process:   450/468, Loss: 0.28764, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   451/468, Loss: 0.16822, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   452/468, Loss: 0.24681, Accuracy:  93.0%\n",
      "Epoch:     0, Process:   453/468, Loss: 0.23679, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   454/468, Loss: 0.32006, Accuracy:  88.3%\n",
      "Epoch:     0, Process:   455/468, Loss: 0.34888, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   456/468, Loss: 0.23233, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   457/468, Loss: 0.33340, Accuracy:  87.5%\n",
      "Epoch:     0, Process:   458/468, Loss: 0.33635, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   459/468, Loss: 0.18399, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   460/468, Loss: 0.30689, Accuracy:  91.4%\n",
      "Epoch:     0, Process:   461/468, Loss: 0.35113, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   462/468, Loss: 0.17394, Accuracy:  96.1%\n",
      "Epoch:     0, Process:   463/468, Loss: 0.27351, Accuracy:  92.2%\n",
      "Epoch:     0, Process:   464/468, Loss: 0.27033, Accuracy:  89.8%\n",
      "Epoch:     0, Process:   465/468, Loss: 0.28540, Accuracy:  90.6%\n",
      "Epoch:     0, Process:   466/468, Loss: 0.24548, Accuracy:  93.8%\n",
      "Epoch:     0, Process:   467/468, Loss: 0.20887, Accuracy:  92.2%\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "for i in range(epoch):\n",
    "    for idx, (train_x, train_y) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(train_x, training=True)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=train_y, from_logits=True))\n",
    "            \n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "\n",
    "        prediction = tf.equal(tf.argmax(logits, -1), tf.argmax(train_y, -1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32)) * 100\n",
    "\n",
    "        print('Epoch: {:5}, Process: {:5}/{}, Loss: {:5.5f}, Accuracy: {:5.1f}%'.format(i, idx, train_dataset_num, loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN 예측 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: tf.Tensor(92.67, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for test_x, test_y in test_dataset:\n",
    "    logits = model(test_x, training=False)\n",
    "    comparison = tf.equal(tf.argmax(logits, -1), tf.argmax(test_y, -1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(comparison, tf.float32)) * 100\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(tf.argmax(model(test_data)[1]))\n",
    "print(test_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_img(i):\n",
    "    plt.title('This is {}'.format(tf.argmax(test_label[i])))\n",
    "    plt.imshow(np.squeeze(test_data[i], -1), cmap='gray')\n",
    "    plt.show()\n",
    "show_img(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
